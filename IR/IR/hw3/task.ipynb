{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оглаживания используйте маленькую коллекцию texts.small.tar.bz2, НО **решения принимаются только по полной коллекции** texts.tar.bz2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_fn = './texts.small.tar.bz2'\n",
    "#input_fn = './texts.tar.bz2'\n",
    "\n",
    "with tarfile.open(input_fn, \"r:bz2\") as tar:\n",
    "    for docid, tarinfo in tqdm(enumerate(tar)):\n",
    "        with tar.extractfile(tarinfo) as inp:\n",
    "            # text = inp.read().decode('utf8')\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод suggest должен возвращать список строк кандидатов на подсказку для префикса. Не более 10 штук.\n",
    "\n",
    "\n",
    "В базовом варианте прделагается реализовать пословные подсказки: предсказывать не более одного слова за раз, для предсказания использовать только введенное пользователем начало слова.\n",
    "\n",
    "\n",
    "Пример: для префикса \"jo\" стоит вернуть самые частые слова начинающиеся на \"jo\", например `[\"john \", \"joker \", \"jojo \"]`. При рассчете частоты не стоит различать строчные и заглавные буквы.\n",
    "\n",
    "\n",
    "НО для префикса \"john c\" следует вернуть самые частые слова начинающиеся на \"с\" и добавить ко всем подсказкам слово \"john\", например `[\"john cycle \", \"john cafe \", \"john coffee \"]`.\n",
    "\n",
    "\n",
    "Если запрос пользователя заканчивается на пробел, значит он собирается ввести новое слово и использовать буквы введенные до пробела в качестве ограничения не стоит. Например, для префикса \"john \" следует вернуть самые частые слова коллекции и добавить ко всем подсказкам слово \"john\", например `[\"john first \", \"john country \", \"john one \"]`.\n",
    "\n",
    "Обратите внимание, что каждая подсказка заканчивается на пробел, тем самым выбрав Вашу подсказку пользователю будет затем предложено новое слово, а не продолжение старого."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest(prefix):\n",
    "    return ['harry', 'potter', 'harry potter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.server\n",
    "import socketserver\n",
    "import json\n",
    "import urllib\n",
    "\n",
    "class DemoHandler(http.server.SimpleHTTPRequestHandler):\n",
    "    def do_GET(self):\n",
    "        parsed = urllib.parse.urlparse(self.path)\n",
    "        if parsed.path == '/demo/suggest.json':\n",
    "            qs = urllib.parse.parse_qs(parsed.query, keep_blank_values=True)\n",
    "            if 'prefix' in qs and len(qs['prefix']) == 1:\n",
    "                data = json.dumps(suggest(qs['prefix'][0])).encode('utf8')\n",
    "                \n",
    "                self.send_response(200)\n",
    "                \n",
    "                self.send_header('Content-type', 'application/json; charset=utf-8')\n",
    "                self.end_headers()\n",
    "                self.wfile.write(data) \n",
    "                return\n",
    "            else:\n",
    "                self.send_response(400)\n",
    "                self.end_headers()\n",
    "                self.wfile.write(b'bad request') \n",
    "                return\n",
    "            \n",
    "        if parsed.path == '/demo/search.json':            \n",
    "            qs = urllib.parse.parse_qs(parsed.query, keep_blank_values=True)\n",
    "            if 'query' in qs and len(qs['query']) == 1:\n",
    "                result = [] if 'search' not in globals() else search(qs['query'][0])                \n",
    "                data = json.dumps(result).encode('utf8')                \n",
    "                self.send_response(200)\n",
    "                \n",
    "                self.send_header('Content-type', 'application/json; charset=utf-8')\n",
    "                self.end_headers()\n",
    "                self.wfile.write(data) \n",
    "                return\n",
    "            else:\n",
    "                self.send_response(400)\n",
    "                self.end_headers()\n",
    "                self.wfile.write(b'bad request') \n",
    "                return            \n",
    "                \n",
    "        http.server.SimpleHTTPRequestHandler.do_GET(self)\n",
    "\n",
    "\n",
    "PORT = 8080\n",
    "with socketserver.TCPServer((\"\", PORT), DemoHandler) as httpd:\n",
    "    print(\"Open demo at http://localhost:%d/demo/demo.html\" % PORT)\n",
    "    httpd.serve_forever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**КОНЕЦ ОБЯЗАТЕЛЬНОЙ ЧАСТИ НА 1 балл**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее идёт описание дополнительный заданий\n",
    "\n",
    "###  1. Саджест\n",
    "#### 1.1  (2 балл) Подсказка словочетаний\n",
    "\n",
    "Выделим из коллекции \"словосочения\": такие минимальные последовательности слов, что ни первое ни последнее не является стоп-словом, и между ними нет знаков препинания. \n",
    "\n",
    "Например: `Lorem Ipsum is simply dummy text of the printing. Printing and typesetting industry.` разбивается на словосочетания `[\"Lorem Ipsum\", \"Ipsum is simply\", \"simply dummy\", \"dummy text\", \"text of the printing\", \"Printing and typesetting\", \"typesetting industry\"]`\n",
    "\n",
    "Скажем, что подсказка подходит префиксу, если последние введенные слова и последние буквы начинаются с данного префикса. Среди подходящих словосочетаний выдайте десятку самых частотных.\n",
    "\n",
    "Таким образом в подсказках должны начать вплывать устойчивые биграмы, например для префикса \"who is john c\" следует вернуть самые частые словосочетания начинающиеся на \"john с\" и добавить ко всем подсказкам слова \"who is \", например `[\"who is john cena \", \"who is john cooper \", \"who is john christopher \"]`.\n",
    "\n",
    "Для префикса \"john \" (с пробелом на конце) следует вернуть самые частые словосочетания начинающиеся на \"john \", например `[\"john kennedy \", \"john f \", \"john cena \"]`. \n",
    "\n",
    "Если подходящих словосочетаний меньше десяти - дополните подсказки обычными пословными подсказками.\n",
    "\n",
    "\n",
    "#### 1.2  (0.5 балла) Подсказка раскладки\n",
    "\n",
    "Если введенный префикс похож на запрос с неправильной раскладкой клавиатуры, предложите подсказки по исправленному запросу.\n",
    "\n",
    "#### 1.3  (2 балл) Подсказка опечаток\n",
    "\n",
    "Если введенных слов нет в словаре, зато есть похожие (отличающиеся небольшой перестановкой букв/заменой букв) - предложите исправление опечатки.\n",
    "\n",
    "### 2 Поиск\n",
    "#### 2.1 (0.5 балла) Кое-какой поиск (обязателен для остальных пунктов 2.*)\n",
    "Реализуйте поиск по всей коллекции документов, в которых есть слова запроса, похожий на тот что был в первой домашней работе.\n",
    "\n",
    "В качестве функции разнижование используте что-то несложное, например tf\\*idf или bm25 из первой домашки.\n",
    "\n",
    "Для того чтобы демка заработала  достаточно реализовать метод search. Пример результата, который ожидается от неё есть ниже в комментарии.\n",
    "\n",
    "\n",
    "#### 2.2 (1 балл) Сниппеты\n",
    "Реализуйте построение сниппета на основе запроса и текста документа. \n",
    "\n",
    "Рассмотрим все подпоследовательности слов документа, суммарной длинны не больше, скажем 300. Среди таких последовательностей выберите такую, которая больше всего \"похожа\" на запрос. В качестве простейшей \"похожести\" можно взять tf\\*idf.\n",
    "\n",
    "Слова из запроса, попавшие в сниппет, стоит выделить html тегом `<b>`\n",
    "\n",
    "\n",
    "#### 2.3 (1 балл) Толковые сниппеты\n",
    "В качестве функции \"похожести\" сниппета за запрос реализуйте что-нибудь более сложное, учитывающие стоят ли слова запроса рядом и стоят ли они в том же порядке, что и в запросе. Предлагается реализовать несколько таких \"принаков похожести\" и скомбинировать их (например линейно).\n",
    "\n",
    "Продемонстрируйте на нескольких запросах превосходство вашей фукнции схожести над базовой.\n",
    "\n",
    "\n",
    "#### 2.4.  (2 балла) Ранжирование\n",
    "Для оценки качества поиска воспользуйтесь файлом ground_truth.txt.gz. В нем в каждой строке записан текст запроса и список документов в порядке убывания \"релевантности\". Точное значение релевантности неизвестно, известен только порядок следования документов.\n",
    "\n",
    "Рассчитайте чиселку качества на основе ground truth. Подберите линейную комбинацию факторов \"tfidf\" и \"tfidf по заголовку\", которая улучшает качество.\n",
    "\n",
    "#### 2.5  (1 балл) Факторы (зависит от 2.4)\n",
    "Рассчитайте с десяток факторов ранжирования. За основу возьмите рузультаты предыдущих лабораторных (bm25, pagerank, etc). Среди факторов должны быть и статические и запросные и динамические.\n",
    "\n",
    "На основе ground truth оценок подберите комбинацию признаков, которая улучшает ранжирование документов.\n",
    "\n",
    "#### 2.6  (1 балл) Учет позиций слов в запросе (зависит от 2.4)\n",
    "Придумайте и реализуйте набор признаков ранжирования, которые награждают за то, что слова в документе идут в том же порядке, что и в запросе.\n",
    "\n",
    "Подберите формулу с учетом новых признаков. Продемонстрируйте, что качество поиска улучшилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    return []\n",
    "    \"\"\"\n",
    "    Каждый документ должен быть описан диктом:\n",
    "      title - строка, заголовок документа - первая строчка в файле\n",
    "      link - урл, имя файла в архиве совпадает с названием документа на сайте википедии\n",
    "      snippet - html, составляется самостоятельно на основе запроса и текста документа\n",
    "\n",
    "    Пример результата работы функции\n",
    "\n",
    "    [{'title': 'Harry Potter',\n",
    "      'link': 'https://simple.wikipedia.org/wiki/Harry_Potter',\n",
    "      'snippet': '<b>Lorem Ipsum</b> is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry\\'s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. ',\n",
    "     },\n",
    "     {'title': 'Таня Гроттер', \n",
    "      'link': 'https://simple.wikipedia.org/wiki/Tanya_Grotter', \n",
    "      'snippet': '<b>Sed ut perspiciatis</b>, unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam eaque ipsa, quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt, explicabo.',\n",
    "     }]\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
